{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_TOKENIZER = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained BPE tokenizer to models/cleared_tokenizer_bpe.json\n"
     ]
    }
   ],
   "source": [
    "if CREATE_TOKENIZER:\n",
    "    from utils import filter_words\n",
    "    from tokenizer import train_bpe_tokenizer\n",
    "    filter_words(\"data/dict.txt\", \"data/cleared_dict.txt\")\n",
    "    train_bpe_tokenizer(\"data/cleared_dict.txt\", vocab_size=28,\n",
    "                        save_path=\"models/cleared_tokenizer_bpe.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'g': 9,\n",
       " 'Ċ': 29,\n",
       " 'k': 13,\n",
       " 'l': 14,\n",
       " 'f': 8,\n",
       " '[MASK]': 2,\n",
       " 'v': 24,\n",
       " 'w': 25,\n",
       " 'p': 18,\n",
       " 'b': 4,\n",
       " 'j': 12,\n",
       " '[UNK]': 1,\n",
       " 'z': 28,\n",
       " 'c': 5,\n",
       " 'u': 23,\n",
       " 'm': 15,\n",
       " 'x': 26,\n",
       " 'd': 6,\n",
       " 'Ġ': 31,\n",
       " 'n': 16,\n",
       " '[PAD]': 0,\n",
       " 't': 22,\n",
       " 'č': 30,\n",
       " 's': 21,\n",
       " 'e': 7,\n",
       " 'o': 17,\n",
       " 'q': 19,\n",
       " 'h': 10,\n",
       " 'y': 27,\n",
       " 'r': 20,\n",
       " 'a': 3,\n",
       " 'i': 11}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizer import load_tokenizer, train_bpe_tokenizer\n",
    "t = load_tokenizer(\"data/cleared_tokenizer_bpe.json\")\n",
    "t.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --words_file data/cleared_dict.txt --out_dir out --tokenizer_path models/cleared_tokenizer_bpe.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_dif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
